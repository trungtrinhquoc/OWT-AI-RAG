{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d733e1a-fff5-4739-b702-cc4af0a69d41",
   "metadata": {},
   "source": [
    "# Combining LCEL Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48386f20-c929-48a9-8720-0953fcd67dd0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65ee060-21f2-4e01-b283-1fd656dac1e9",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell\n",
    "\n",
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook.\n",
    "\n",
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 007-main-ops-lcel-chain.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18edd454-6d12-445d-b4f9-b228097a1724",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a63ff6-99ff-4629-b965-547d12a99ba6",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **007-main-ops-lcel-chain**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b3c1ba-c90e-4360-930b-d2ff39296e4a",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eaa23c-5e9b-4098-9aa4-9950807d1ce4",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d5fca6e-8eed-4ac3-abf8-e96862671a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "992ec4a9-aa01-4e44-aeb9-b9a1f3aa9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "google_api_key = os.environ[\"GOOGLE_API_KEY\"]\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01d18b-f9f0-427b-a9dc-3d1885160578",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e0c516-fb73-4604-be63-c9d432411be0",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c62afa07-b12c-45d4-a99e-04fe68f7f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed746499-d1b8-41e5-b131-270cf5fa229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain lanchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2af3ef-c2c7-445f-92bd-a29c68abce25",
   "metadata": {},
   "source": [
    "## Connect with an LLM and start a conversation with it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb756f6-05a3-41d7-9c58-ef9f02f590c1",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fa7337f-3d60-4ede-bdf8-aa7a5cffec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3551e-95ca-41a1-8810-89c495bf93ab",
   "metadata": {},
   "source": [
    "* For this project, we will use OpenAI's gpt-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9afcbc7d-a816-41e3-925f-850883f5770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7f207a-fdb9-46cf-b1c0-06fbcf9b5e99",
   "metadata": {},
   "source": [
    "## Coercion: a chain inside another chain\n",
    "* Remember: almost any component in LangChain (prompts, models, output parsers, etc) can be used as a Runnable.\n",
    "* **Runnables can be chained together using the pipe operator `|`. The resulting chains of runnables are also runnables themselves**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51ba28a5-a605-482a-b3df-43a70e4dc352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a sentence about {politician}\")\n",
    "\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=google_api_key)\n",
    "\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d91592b-027a-4ea4-a764-94bf27b8610f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neville Chamberlain, as Prime Minister of Britain, pursued a policy of appeasement towards Nazi Germany in the lead-up to World War II.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Chamberlain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82645057-4570-4dd9-ad3b-58f0365bb4eb",
   "metadata": {},
   "source": [
    "#### Coercion: combine a chain with other Runnables to create a new chain.\n",
    "* See how in the `composed_chain` we are including the previous `chain`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c8f1937-227a-4d4f-9e62-2b6792f00541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "historian_prompt = ChatPromptTemplate.from_template(\"Was {politician} positive for Humanity?\")\n",
    "\n",
    "composed_chain = {\"politician\": chain} | historian_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f98a3705-a6b0-473f-b4b8-7edd2dff9831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Most historians and the general public view Abraham Lincoln as having a profoundly positive impact on humanity. Here's why:\\n\\n*   **Preservation of the Union:** Lincoln's leadership during the Civil War was crucial in preventing the permanent fracturing of the United States. He believed in the importance of a unified nation and fought to maintain it.\\n*   **Abolition of Slavery:** While his initial focus was on preserving the Union, Lincoln's views on slavery evolved. The Emancipation Proclamation, though initially a military strategy, ultimately paved the way for the complete abolition of slavery in the United States. This was a monumental step forward for human rights and equality.\\n*   **Moral Leadership:** Lincoln's speeches and writings often emphasized the importance of equality, justice, and the rights of all people. He provided moral leadership during a time of great division and uncertainty.\\n*   **The 13th Amendment:** Lincoln played a significant role in the passage of the 13th Amendment to the Constitution, which formally abolished slavery in the United States.\\n*   **Vision for Reconstruction:** Lincoln had a vision for a relatively lenient and reconciliatory Reconstruction process after the Civil War. While his assassination prevented him from fully implementing this vision, it reflected his desire for healing and unity.\\n\\nHowever, it is important to consider some criticisms and complexities:\\n\\n*   **Initial War Aims:** Lincoln's initial aim in the Civil War was to preserve the Union, even if it meant not freeing the slaves. His priority was the nation's survival, and his views on emancipation evolved over time.\\n*   **Treatment of Native Americans:** Lincoln's administration oversaw policies that negatively impacted Native American tribes, including displacement and conflict.\\n*   **Wartime Measures:** Lincoln's administration took some controversial measures during the Civil War, such as suspending habeas corpus, which raised concerns about civil liberties.\\n\\n**In conclusion:** While not without complexities and criticisms, Abraham Lincoln is overwhelmingly considered to have had a positive impact on humanity due to his leadership in preserving the Union, abolishing slavery, and advocating for equality and justice.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_chain.invoke({\"politician\": \"Lincoln\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b650952f-a0b1-404e-ac63-1a11ed4f347e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Attila the Hun was definitely not positive for humanity. His military campaigns across Europe in the 5th century were characterized by widespread violence, destruction, and immense suffering.\\n\\nHere\\'s why he\\'s considered a destructive figure:\\n\\n*   **Brutal Warfare:** The Huns, under Attila\\'s leadership, were known for their ruthless tactics, including pillaging, looting, and massacring entire populations.\\n*   **Widespread Devastation:** Attila\\'s campaigns led to the destruction of countless settlements and infrastructure, disrupting economies and causing widespread famine.\\n*   **Forced Displacement:** The Hunnic invasions forced many people to flee their homes, creating refugee crises and contributing to the instability of the late Roman Empire.\\n*   **Fear and Terror:** Attila\\'s reputation as the \"Scourge of God\" instilled fear and terror throughout Europe, leading to social and political upheaval.\\n\\nWhile some historians argue that the Hunnic invasions indirectly contributed to the decline of the Roman Empire and the rise of new political entities, the immediate impact of Attila\\'s actions was overwhelmingly negative for the people who lived through them.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "composed_chain.invoke({\"politician\": \"Attila\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4cebf2-c24f-4bb5-bb8f-bcd2daf72f82",
   "metadata": {},
   "source": [
    "## Another example: a chain inside another chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "172fd045-567e-40bc-8e42-e8f3923ca1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"L'Europe.\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(\"what is the country {politician} is from?\")\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"what continent is the country {country} in? respond in {language}\"\n",
    ")\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=google_api_key)\n",
    "\n",
    "chain1 = prompt1 | model | StrOutputParser()\n",
    "\n",
    "chain2 = (\n",
    "    {\"country\": chain1, \"language\": itemgetter(\"language\")}\n",
    "    | prompt2\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain2.invoke({\"politician\": \"Miterrand\", \"language\": \"French\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e51df-c2fc-47d5-85d4-c4717bf32603",
   "metadata": {},
   "source": [
    "## Fallback for Chains\n",
    "* When working with language models, you may often encounter issues from the underlying APIs, whether these be rate limiting or downtime. Therefore, as you go to move your LLM applications into production it becomes more and more important to safeguard against these. That's why LangChain introduced the concept of fallbacks.\n",
    "* A fallback is an alternative plan that may be used in an emergency.\n",
    "* Fallbacks can be applied not only on the LLM level but on the whole runnable level. This is important because often times different models require different prompts. So if your call to OpenAI fails, you don't just want to send the same prompt to Anthropic - you probably want to use a different prompt template and send a different version there.\n",
    "* We can create fallbacks for LCEL chains. Here we do that with two different models: ChatOpenAI (with a bad model name to easily create a chain that will error) and then normal OpenAI (which does not use a chat model). Because OpenAI is NOT a chat model, you likely want a different prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "509b9f90-648c-48da-acbf-206519e74966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's create a chain with a ChatModel\n",
    "# We add in a string output parser here so the outputs between the two are the same type\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You're a funny assistant who always includes a joke in your response\",\n",
    "        ),\n",
    "        (\"human\", \"Who is the best {sport} player worldwide?\"),\n",
    "    ]\n",
    ")\n",
    "# Here we're going to use a bad model name to easily create a chain that will error\n",
    "chat_model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=google_api_key)\n",
    "\n",
    "bad_chain = chat_prompt | chat_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d75321e-ec9c-41a3-9377-1b26d7ced7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets create a chain with the normal OpenAI model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "prompt_template = \"\"\"Instructions: You're a funny assistant who always includes a joke in your response.\n",
    "\n",
    "Question: Who is the best {sport} player worldwide?\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=google_api_key)\n",
    "\n",
    "good_chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30b6231c-ef6e-4d18-ba22-b92888e515cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, the age-old question! Declaring the \"best\" soccer player is like trying to pick the best flavor of ice cream – everyone has their own favorite!\\n\\nCurrently, it\\'s a hot debate between Lionel Messi and Cristiano Ronaldo, with some rising stars like Kylian Mbappé also entering the conversation. Each player has unique strengths and accomplishments that make them top contenders.\\n\\nBut, if you ask me, the best soccer player is always the one who brings the most snacks to the game!\\n\\nWhy did the soccer ball quit the team?\\nBecause it was tired of being kicked around!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now create a final chain which combines the two\n",
    "chain = bad_chain.with_fallbacks([good_chain])\n",
    "\n",
    "chain.invoke({\"sport\": \"soccer\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d99ae33-c4e7-42eb-b65e-82ce3260f9c3",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 007-main-ops-lcel-chain.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 007-main-ops-lcel-chain.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0688402d-d575-4339-b3e8-35da12e89e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b403-RJfSVSKc-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
